{"componentChunkName":"component---src-templates-blog-post-js","path":"/week04/hash-table/","result":{"data":{"site":{"siteMetadata":{"title":"Blog"}},"markdownRemark":{"id":"829e409c-3b55-5a4f-893b-2823cc7eb3ca","excerpt":"Overview Hash Table or Hash Map is a data structure use a hash function to map a key to an index into an array of buckets. Hash collisions: when the hash…","html":"<h1>Overview</h1>\n<p>Hash Table or Hash Map is a data structure use a hash function to map a key to an index into an array of buckets.</p>\n<p>Hash collisions: when the hash function generates the same index for more than one key.</p>\n<p>In many situations, hash tables on average more efficient than search trees. Widely used databse indexing, caches…</p>\n<h1>Hashing</h1>\n<p><code class=\"language-text\">index = hash_func(key) % array_size</code></p>\n<p>when array size is power of two, modulo operator reduced to masking => improve speed.</p>\n<p>Hash function should provide a uniform distribution of hash values. When use dynamic resizing with exact doubling and halving of the table size, uniform need when table size is power of 2. Some  hash algorithm prefer size is a prime.</p>\n<p>Cryptographic hash functions are believed to provide good hash functions for any table size.</p>\n<p>If all keys are known ahead of time, a perfect hash function can be used.</p>\n<h1>Load factor</h1>\n<p><code class=\"language-text\">load factor = size / capacity</code></p>\n<ul>\n<li>load factor to small: waste memory</li>\n<li>load factor to large: slow operator</li>\n</ul>\n<h1>Collison resolution</h1>\n<ul>\n<li>\n<p>Birthday problem</p>\n<ol>\n<li>\n<p>Chaining\n1.1. Chaining with linked lists</p>\n<ul>\n<li>poor cache performance.\n1.2. Chaining with head list</li>\n<li>Pointer traveser decreased by one</li>\n<li>Increase cache efficiency</li>\n<li>Empty bucket takes the same space as a bucket with one entry\n1.3. Chaining with seft-balance binary search tree</li>\n<li>Complexity (insert, delete, lookup) => O(logn)</li>\n<li>Add extra complexity, may cause worse performance for smaller tables. when time spent inserting into and balancing the tree > time needed to perform a linear search.</li>\n<li>Java 8 uses binary search tree for buckets\n1.4. Chainging with dynamic array</li>\n<li>Efficient use caching and <a href=\"https://en.wikipedia.org/wiki/Translation_lookaside_buffer\">TLB</a></li>\n<li>Exact-fit</li>\n<li>Growing by block sizes or pages</li>\n<li>Dynamic perfect hashing: use n^2 worst case, n * k on avarage memory. Constant worst-cas lookup time, low amortized insertion time, possible to use <a href=\"https://en.wikipedia.org/wiki/Fusion_tree\">fusion tree</a> to achieve constant time for all operator with high probability.</li>\n</ul>\n</li>\n<li>\n<p>Open addressing\n2.1. Linear probing</p>\n<ul>\n<li>Interval probes is fixed (usually 1).</li>\n<li>Good CPU cache</li>\n<li>Widely used\n2.2. Quadratic probing\n2.3. Double hashing</li>\n</ul>\n</li>\n<li>Performance dramatically degrades when the load factor grows beyond 0.7 or so</li>\n<li>Only saves memory if the entries are small (less than four times the size of a pointer), and the load factor is not too small.</li>\n<li>Avoids the time overhead of allocating each new entry record</li>\n<li>Avoids the extra indirection required to access the first entry of each bucket.</li>\n<li>Poor choice for large elements, because these elements fill entire CPU cache line.</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Coalesced_hashing\">Coalesced hasing</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Cuckoo_hashing\">Cuckoo hasing</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Hopscotch_hashing\">Hopscotch hasing</a></li>\n<li>Robin Hood hashing</li>\n<li>2-choice hashing</li>\n</ol>\n</li>\n</ul>\n<h1>Dynamic resizing</h1>\n<ul>\n<li>\n<p>Resizing by copying all entries</p>\n<ul>\n<li>Automatically trigger when the load factor exceeds some threshold rmax, rmix</li>\n</ul>\n</li>\n<li>\n<p>Alternatives</p>\n<ul>\n<li>Incremental resizing</li>\n<li>During the resize, allocate the new hash table, keep the old table unchanged</li>\n<li>In each lookup, delete operation, check both tables</li>\n<li>Perform insertion operations only in the new table</li>\n<li>At each inseartion also move r element from old table to the new table.</li>\n<li>When all elements are removed from the old table, deallocate it.</li>\n<li>Increase the size by a factor of at least <code class=\"language-text\">(r+1)/r</code> during resizing</li>\n<li>Monotonic keys</li>\n<li>When key monotonically increasing/decreasing order, we can use <a href=\"https://en.wikipedia.org/wiki/Consistent_hashing\">consistent hashing</a></li>\n<li>Linear hashing: two possible lookup functions</li>\n<li>Hashing for distributed hash tables:</li>\n<li>Choose a hash function in such a way that the hashes of most values do not change when table is resized.</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Rendezvous_hashing\">Rendezvous hashing</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Consistent_hashing\">Consistent hasing</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Content_addressable_network\">Content addressable network</a> algorithm</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Kademlia\">Kademlia</a> distance</li>\n</ul>\n</li>\n</ul>\n<h1>Advantages</h1>\n<h1>Drawbacks</h1>\n<h1>References</h1>\n<p><a href=\"https://en.wikipedia.org/wiki/Hash_table\">https://en.wikipedia.org/wiki/Hash_table</a></p>","frontmatter":{"title":"Hash table","date":"July 30, 2020","description":"Hash table"}}},"pageContext":{"slug":"/week04/hash-table/","previous":{"fields":{"slug":"/week04/oop/"},"frontmatter":{"title":"OOP"}},"next":{"fields":{"slug":"/week05/gRPC/"},"frontmatter":{"title":"gRPC"}}}},"staticQueryHashes":["2103919173","2841359383"]}
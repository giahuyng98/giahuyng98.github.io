{"componentChunkName":"component---src-templates-blog-post-js","path":"/mysql/mysql/","result":{"data":{"site":{"siteMetadata":{"title":"Blog"}},"markdownRemark":{"id":"8944835a-ecc8-58e6-9734-cf6e18a05eb8","excerpt":"MySQL Architecture Clients => Connection/Thread handling, Parser, Cache, Optimizer => Storage engine Each connection get a thread Server caches threads 5.…","html":"<h2>MySQL Architecture</h2>\n<p>[Clients] => [Connection/Thread handling, Parser, Cache, Optimizer] => [Storage engine]</p>\n<ul>\n<li>Each connection get a thread</li>\n<li>Server caches threads</li>\n<li>5.5 support thread pooling plugins</li>\n<li>Queries => [parsed tree] => [optimize]</li>\n<li>Queries => [cache] =></li>\n<li>Concurrency: shared lock &#x26; exclusive locks/ read lock &#x26; write lock</li>\n<li>Table lock: write locks have higher prority than read locks</li>\n<li>Row lock: </li>\n<li>alter table: mysql use its own lock, not storage engine</li>\n<li>Multiversion Concurrency control</li>\n<li>!= row locking</li>\n<li>use row-level locking</li>\n<li>work with read commited &#x26; repeatable read</li>\n</ul>\n<h2>Default order</h2>\n<ul>\n<li>FROM/JOIN</li>\n<li>WHERE</li>\n<li>GROUP BY</li>\n<li>HAVING</li>\n<li>WINDOW FUNCTION</li>\n<li>SELECT</li>\n<li>DISTINCT</li>\n<li>UNION</li>\n<li>ORDER BY</li>\n<li>LIMIT/OFFSET</li>\n</ul>\n<h2>Optimize SELECT</h2>\n<ul>\n<li>Index</li>\n<li>Isolate and tune part of the query</li>\n<li>Minimize/avoid full table scan</li>\n<li>ANALYZE TABLE</li>\n<li>Tuning, indexing, configuration that are specific to the storage engine</li>\n<li>Optimize single-query transactions for InnoDB</li>\n<li>Avoid make queries too hard to understand</li>\n<li>EXPLAIN</li>\n<li>Size/properties cache</li>\n<li>Deal with lock</li>\n</ul>\n<h2>WHERE</h2>\n<ul>\n<li>\n<p>MySQL automatic optimize:</p>\n<ul>\n<li>Removal of unnecessary parentheses</li>\n<li>Constant folding</li>\n<li>Constant condition removal</li>\n<li>Constant expressions used by indexes are evaluated only once</li>\n<li><code class=\"language-text\">COUNT(*)</code> on single table without WHERE return directly MyISAM, MEMORY</li>\n<li>Early detection invalid constant expressions</li>\n<li>HAVING is merged with WHERE if not using GROUP BY or aggeregate functions</li>\n<li>Each table in join, a simple WHERE => a fast WHERE</li>\n<li>Constant tables are read first: (0, 1) record/ WHERE on PRIMARY KEY, UNIQUE INDEX constant expression, NOT NULL</li>\n<li>index may not be used over full-scan</li>\n<li>in some case, my sql can read rows from the index-tree, not data file, (numeric index)</li>\n</ul>\n</li>\n</ul>\n<h2>InnoDB</h2>\n<ul>\n<li>ACID, MVCC</li>\n<li>table space</li>\n<li>index and data seperate files</li>\n<li>clustered index</li>\n<li><strong>secondary indexes contain the primary key column</strong></li>\n<li>optimization: predictive read ahead, <strong>adaptive hash index</strong>, insert buffer</li>\n<li>hot backup</li>\n</ul>\n<h2>Match against</h2>\n<ul>\n<li>match(column) against (‘str1,str2’)</li>\n<li>match(column) against (‘str1,str2’ in natural language mode)</li>\n<li>ft<em>min</em>word_len = 3</li>\n<li>stop word</li>\n</ul>\n<h2>Optimizing schema</h2>\n<ul>\n<li>Smaller usually better</li>\n<li>Simple is good</li>\n<li>Avoid NULL if possible (exeptions: InnoDBstores NULL with a single bit)</li>\n<li>computations generally use 64-bit BIGINT integers, even on 32-bit architectures</li>\n<li>DECIMAL</li>\n<li>[more…]</li>\n</ul>\n<h2>Index</h2>\n<ul>\n<li>InnoDB use B+Trees</li>\n<li>\n<p>Type of queries that can use B-tree index:</p>\n<ul>\n<li>Match full</li>\n<li>Match a left most prefix</li>\n<li>Match a range of value</li>\n<li>Match part exactly - part range</li>\n<li>Index only queries </li>\n</ul>\n</li>\n<li>indexes help <code class=\"language-text\">ORDER BY</code> clause</li>\n<li>Hash indexes</li>\n<li>MEMORY is the only engine that explicit support hash index</li>\n<li>Collison resolve by linked list</li>\n<li>Limitation…(can use for sorting, index only queries, partical matching, equality only comparisons, collison performance lookup and maintain)</li>\n<li>InnoDB adaptive hash indexes</li>\n<li><strong>Build own hash index</strong>: create separate column (use trigger, …)</li>\n<li>CRC32(‘str’), FNV64()</li>\n<li>Birthday paradox</li>\n<li>Spatial (R-Tree) indexes</li>\n<li>\n<p>Fulltext indexes</p>\n<ul>\n<li>Stopwords</li>\n<li>Stemming</li>\n<li>Plurals</li>\n<li>Boolean searching</li>\n</ul>\n</li>\n<li>TokuDB use fractal tree indexes</li>\n<li>ScaleDB use Patricia tries…</li>\n<li>\n<p>Indexes benefits</p>\n<ul>\n<li>Reduce amount of data the server has to examine</li>\n<li>Help server avoid sorting and temporary tables</li>\n<li>Turn random IO to sequential IO</li>\n</ul>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">- Quickly navigate\n- Order, group by optimize\n- Relative value close together\n- Index store copy of a value -&gt; index only queries</code></pre></div>\n<ul>\n<li><strong>Three-star index</strong></li>\n<li><strong>1 star</strong> if it place relevent row adjacent to each other</li>\n<li><strong>2 star</strong> if its rows are sort in the order the query need</li>\n<li><strong>3 star</strong> if it contains all the column needed for the query</li>\n</ul>\n<p>=> Small table: often more effective to read all the rows</p>\n<p>=> Medium to large table: good to use</p>\n<p>=> Enormous tables: may not good maintaince indexes, partitioning</p>\n<ul>\n<li><strong>use sumary table</strong></li>\n<li>\n<p>Indexing strategies</p>\n<ul>\n<li>Isolating the column (<code class=\"language-text\">WHERE idx_col + 1 &lt; 100</code> => <code class=\"language-text\">WHERE idx_col &lt; 100 - 1</code>)</li>\n<li>Prefix Index: long enough to give good selective, short enough to save space, <em>Selectivity</em></li>\n<li>Multicolumn indexes: index merging optimization</li>\n<li>Place ordering: most selective column first less important than avoiding I/O and sorting</li>\n<li>Correct order depends on the queries that will use the index</li>\n</ul>\n</li>\n<li>Clustered indexes</li>\n<li>\n<p>Advantages: </p>\n<ul>\n<li>Related data close together.</li>\n<li>Data access is fast</li>\n<li>Queries that use covering indexes can use primary key values contained at the leaf nodes???</li>\n</ul>\n</li>\n<li>\n<p>Disavantages:</p>\n<ul>\n<li>Improve performance only on I/O-bound workload</li>\n<li>Insert speed heavily on insertion order.</li>\n<li>Update is expensive</li>\n<li>page splits: row must be placed into a page that is full of data</li>\n<li>can be slower for full table scan: page split</li>\n<li>Secondary (nonclustered) index can be large (contain primary key)</li>\n<li>Secondary index accesses require 2 index lookup</li>\n</ul>\n</li>\n<li>MyISAM data layout: 1 Btree per 1 index, ref only</li>\n<li>InnoDB data layout: Clustered, Node{PK, TranID, Rollback Pointer, Columns…}, leaf node secondary index contain primary key</li>\n<li>Inserting rows in primary key order with InnoDB: mostly benefic but for high concurrency workloads suffer from hot spot primary insert lock,\nAUTO<em>INCREMENT innodb</em>autoinc<em>lock</em>mode,</li>\n<li>\n<p>Covering indexes</p>\n<ul>\n<li>An index that contains (covers) all the data needed to satisfy query is called a covering index</li>\n</ul>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">EXPLAIN SELECT * FROM products WHERE actor=&#39;SEAN CARREY&#39; AND title like &#39;%APOLLO%&#39;\\G\n- Index can&#39;t cover this query: 1-select * but index (actor, title), 2-mysql can&#39;t perform LIKE operation in the index, leading wildcard\nEXPLAIN SELECT *  FROM products    JOIN (    SELECT prod_id    FROM products    WHERE actor=&#39;SEAN CARREY&#39; AND title LIKE &#39;%APOLLO%&#39;    ) AS t1 ON (t1.prod_id=products.prod_id)\\G</code></pre></div>\n<p>** indexcondition pushdown mysql 5.6</p>\n<ul>\n<li>\n<p>Using Index Scans for Sorts</p>\n<ul>\n<li>Mysql has 2 ways to produce ordered results: 1-sort operator, 2-index (EXPLAIN type=index)</li>\n<li>Scan index is fast, but if it’s not an covering index => random I/O</li>\n<li>Ordering work only when the index’s order is exactly the same as the ORDER BY</li>\n<li>And in multiple join table ORDER BY colums in the first table</li>\n</ul>\n</li>\n<li>\n<p>Packed (Prefix compressed) indexes</p>\n<ul>\n<li>Used by MyISAM</li>\n<li>Allow more index to fit in memory</li>\n<li>Pack string (even integer)</li>\n<li>Store 1 full lenght + others suffix</li>\n<li>Can’t use binary search, sequencial scaning only</li>\n<li>1/10 size of the disk</li>\n<li>PACK_KEYS</li>\n</ul>\n</li>\n<li>\n<p>Duplicate indexes, redundant indexes</p>\n<ul>\n<li>Duplicate indexes should be remove</li>\n<li>Redundant indexes may be need for performance reasons.</li>\n<li>In most cases should extend existing indexes</li>\n<li>Identify Duplicate/Redundant indexes => 1-INFORMATION_SCHEMA, 2-common-schema framework, 3-pt-duplicate-key-checker</li>\n<li>index (A, ID) =>  WHERE A = 5 ORDER BY ID</li>\n<li>index (A, B, ID) => not so good => filesort</li>\n</ul>\n</li>\n<li>\n<p>Unused indexes</p>\n<ul>\n<li>INFORMATION<em>SCHEMA.INDEX</em>STATISTICS</li>\n<li>Tooling</li>\n</ul>\n</li>\n<li>\n<p>Indexes and locking</p>\n<ul>\n<li>Indexes permit queries to lock fewer rows</li>\n<li>But this only works if InnoDB can filter out the undesired rows at <em>the storage engine level</em></li>\n</ul>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">EXPLAIN SELECT actor_id FROM sakila.actor \nWHERE actor_id &lt; 5 AND actor_id &lt;&gt; 1 FOR UPDATE;\n\nlock actor_id 1 =&gt; 5</code></pre></div>\n<ul>\n<li>can be worse when InnoDB can’t use index to find and lock a row, full table scan => locks every row</li>\n<li>Case study</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">we need to design an online dating site with user profiles that have manydifferent columns, such as \nthe user’s country, state/region, city, sex, age, eye color, andso on. \nThe site must support searching the profiles by various combinations of theseproperties. \nIt must also let the user sort and limit results by the last time the profile’sowner was online, \nratings from other members, etc. How do we design indexes for suchcomplex requirements?</code></pre></div>\n<ul>\n<li>Index base sorting OR post retrieval sorting</li>\n<li>\n<p>Support many kind of filtering</p>\n<ul>\n<li>Columns have many distinct values VS columns appear most often in WHERE clause</li>\n<li>(sex, country): 1-sex appear almost every queries, 2- <code class=\"language-text\">AND SEX IN(&#39;m&#39;, &#39;f&#39;)</code></li>\n<li>Combine indexes </li>\n<li>Range index shoule be at the end of composite index, or IN (a,b,c,d…)</li>\n</ul>\n</li>\n<li>\n<p>Avoid multiple range conditions</p>\n<ul>\n<li>IN()</li>\n<li>Precompute column last_active => active{0, 1}</li>\n<li>Separate indexes</li>\n</ul>\n</li>\n<li>\n<p>Optimize sort</p>\n<ul>\n<li>index on (sex, rating)</li>\n<li>SELECT<cols>FROM profiles WHERE sex=‘M’ ORDER BY rating LIMIT 10;</li>\n<li>Slow SELECT<cols>FROM profiles WHERE sex=‘M’ ORDER BY rating LIMIT 100000, 10;</li>\n<li>=> denormalizing, precomputing, caching</li>\n<li>Deferred join:</li>\n</ul>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SELECT&lt;cols&gt;FROM profiles INNER JOIN (    \n  SELECT&lt;primary key cols&gt;FROM profiles \n  WHERE x.sex=&#39;M&#39; ORDER BY rating LIMIT 100000, 10 \n) AS x USING(&lt;primary key cols&gt;);</code></pre></div>\n<h3>Index and Table Maintenance</h3>\n<ul>\n<li>\n<p>Finding and Repairing Table Corruption</p>\n<ul>\n<li><code class=\"language-text\">CHECK TABLE</code></li>\n<li><code class=\"language-text\">ALTER TABLE innodb_tbl ENGINE=INNODB</code></li>\n<li><code class=\"language-text\">myi-samchk</code></li>\n<li><code class=\"language-text\">innodb_force_recovery</code></li>\n<li><code class=\"language-text\">Percona InnoDB Data Recovery Toolkit</code></li>\n</ul>\n</li>\n<li>\n<p>Updating Index Statistics</p>\n<ul>\n<li><code class=\"language-text\">records_in_range()</code>:  returns the number of records in that range</li>\n<li><code class=\"language-text\">info()</code>: return various types of data, including indexcardinality (approximately how many records there are for each key value)</li>\n<li>Cost base optimizer, statistics ANALYZE TABLE</li>\n<li><code class=\"language-text\">SHOW INDEX FROM tbl</code></li>\n</ul>\n</li>\n<li>Reducing Index and Data Fragmentation</li>\n<li>Sumary\n`</li>\n<li>Single-row access is slow, especially on spindle-based storage. (Solid-state disksare faster at random I/O, but this point remains true.)\nIf the server reads a blockof data from storage and then accesses only one row in it, it wastes a lot of work.It’s much better to read in a\nblock that contains lots of rows you need. Use indexesto create locality of reference for improved efficiency.</li>\n<li>Accessing ranges of rows in order is fast, for two reasons. First, sequential I/Odoesn’t require disk seeks, so it is faster than random I/O,\nespecially on spindle-based storage. Secondly, if the server can read the data in the order you need it, itdoesn’t need to perform any follow-up\nwork to sort it, and GROUP BY queries don’tneed to sort and group rows together to compute aggregates over them.</li>\n<li>Index-only access is fast. If an index contains all the columns that the query needs,the storage engine doesn’t need to find the other columns\nby looking up rows inthe table. This avoids lots of single-row access, which as we know from point 1above is slow.\n`</li>\n</ul>\n<h2>Optimizing select</h2>\n<ul>\n<li>Only asking for what you really need (rows, cols), unless you know what you are doing, and becareful with repeated fetch</li>\n<li>Response time</li>\n<li>Rows examined</li>\n<li>Rows returned</li>\n<li>\n<p>Rows examined: WHERE clause can apply 3 ways from best to worst</p>\n<ul>\n<li>Index lookup to eliminate non matching rows, storage engine layer</li>\n<li>Use a covering index <code class=\"language-text\">Extra: Using Index</code> to avoid row accesses and filter out non matching rows, server layer</li>\n<li>Retrieve -> filter rows , server layer</li>\n<li><code class=\"language-text\">SELECT actor_id, COUNT(*) FROM sakila.film_actor GROUP BY actor_id;</code> An index can’t reduce the number of rows examined for a query like this one</li>\n<li>If a huge number of rows were examined to produce relatively few rows in the result: 1-use covering indexes, 2-change the schema (sumary table), 3-Rewrite a complicate query</li>\n</ul>\n</li>\n<li>Whether it’s preferable to break up a complexquery into several simpler queries</li>\n<li>\n<p>Chopping up a query</p>\n<ul>\n<li>From: <code class=\"language-text\">DELETE FROM messages WHERE created &lt; DATE_SUB(NOW(),INTERVAL 3 MONTH);</code></li>\n<li>To: </li>\n</ul>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">rows_affected = 0\ndo {\n  rows_affected = do_query(&quot;DELETE FROM messages WHERE created &lt; DATE_SUB(NOW(),INTERVAL 3 MONTH) LIMIT 10000&quot;)\n} while rows_affected &gt; 0</code></pre></div>\n<ul>\n<li>Join Decomposition</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SELECT * FROM tag \nJOIN tag_post ON tag_post.tag_id=tag.id\nJOIN post ON tag_post.post_id=post.id\nWHERE tag.tag=&#39;mysql&#39;;</code></pre></div>\n<p>to:</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SELECT * FROM  tag WHERE tag=&#39;mysql&#39;;\nSELECT * FROM  tag_post WHERE tag_id=1234;\nSELECT * FROM  post WHERE  post.id in (123,456,567,9098,8904);</code></pre></div>\n<ul>\n<li>\n<p>performance advantages:</p>\n<ul>\n<li>caching can be more efficient. </li>\n<li>executing the queries individually can sometimes reduce lock contention.</li>\n<li>doing joins in the application makes it easier to scale the database by placing tables on different servers</li>\n<li>the queries themselves can be more efficient. In this example,\nusing an IN() list instead of a join lets MySQL sort row IDs and retrieve rows more optimally than might be possible with a join</li>\n<li>reduce redundant row accesses</li>\n<li>manual hash join</li>\n</ul>\n</li>\n<li>\n<p>Query execution</p>\n<ul>\n<li>Client send sql statement</li>\n<li>Server check cache, if hit return result</li>\n<li>Server parses, preprocessing, and optimize the SQL into a query execition plan</li>\n<li>Query execution engine executes the plan by making calls to the storage engine API</li>\n<li>Server send server to the client</li>\n</ul>\n</li>\n<li>\n<p>Client/Server protocol</p>\n<ul>\n<li>half duplex: client (or server) must receive (or sent) all data before sent (or receive) new one, <code class=\"language-text\">LIMIT</code></li>\n<li><code class=\"language-text\">max_allowed_packet</code></li>\n<li>client fetchs all the result set and store in memory or fetchs invidiual row, important for server: locking, free resource…</li>\n</ul>\n</li>\n<li>\n<p>Query state</p>\n<ul>\n<li>Sleep</li>\n<li>Query</li>\n<li>Locked</li>\n<li>Analyzing and statistics</li>\n<li>Copying to tmp table [on disk]</li>\n<li>Sorting result</li>\n<li>Sending data: between states, or to the client</li>\n</ul>\n</li>\n<li>Query cache: case sensitive hash lookup, => check privileges => return</li>\n<li>\n<p>Parser and preprocessor:</p>\n<ul>\n<li>Parser parse sql syntax => parse tree</li>\n<li>Preprocessor check parse tree: table exists, column exists, alias…</li>\n<li>Preprocessor check privileges</li>\n</ul>\n</li>\n<li>\n<p>Query optimizer</p>\n<ul>\n<li><code class=\"language-text\">Last_query_cost</code></li>\n<li>static/dynamic</li>\n<li>types of optimization:</li>\n<li>Reordering joins</li>\n<li>Converting outer join to inner join</li>\n<li>Applying algebraic equivalence rules</li>\n<li>COUNT(), MIN(), MAX() optimizations</li>\n<li>Evaluating and reducing constant expressions</li>\n<li>Covering indexes</li>\n<li>Subquery optimization</li>\n<li>Early termination</li>\n<li>Equality propagation</li>\n<li><code class=\"language-text\">IN()</code> list comparisons: mysql sorts the list => O(logn)</li>\n<li>And many more…</li>\n</ul>\n</li>\n<li>MySQL’s join execution strategy</li>\n<li><strong>every query a join — not just every query that matches rows from two tables, but every query, period</strong></li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SELECT tbl1.col1, tbl2.col2 \nFROM tbl1 INNER JOIN tbl2 USING(col3) \nWHERE tbl1.col1 IN(5,6);</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">outer_iter = iterator over tbl1 where col1 IN(5,6)\nouter_row  = outer_iter.next\nwhile outer_row   \n  inner_iter = iterator over tbl2 where col3 = outer_row.col3   \n  inner_row  = inner_iter.next   \n  while inner_row      \n    output [ outer_row.col1, inner_row.col2 ]      \n    inner_row = inner_iter.next   \n  end   \n  outer_row = outer_iter.next\nend</code></pre></div>\n<ul>\n<li>\n<p>Execution plan</p>\n<ul>\n<li><code class=\"language-text\">EXPLAIN EXTENDED</code> + <code class=\"language-text\">SHOW WARINGS</code></li>\n<li><code class=\"language-text\">STRAIGHT_JOIN</code></li>\n<li><code class=\"language-text\">optimizer_search_depth</code> variable</li>\n<li>n-factorial combinations of join orders to examine</li>\n<li>MySQL has many heuristics, to speed up the optimization stage</li>\n<li>Sometime queries can be reordered (LEFT JOIN, correlated sub queries), reduce search space</li>\n</ul>\n</li>\n<li>\n<p>Sort optimizations</p>\n<ul>\n<li>filesort: quick sort or quick sort + merge from disk if data won’t fit sort buffer</li>\n<li>2 filesort algorithms:</li>\n<li>Two passes: sort the pointer than read data</li>\n<li>Single pass: read all column needed => sort => output <code class=\"language-text\">max_length_for_sort_data</code></li>\n<li>allocates fixed-size record for each tuple</li>\n<li>sort a join: order by (cols from tb1) => sort then join <code class=\"language-text\">Using filesort”</code> otherwise <code class=\"language-text\">Using temporary; Using filesort</code></li>\n<li>mysql 5.6 <code class=\"language-text\">LIMIT</code> sort optimize</li>\n</ul>\n</li>\n<li>\n<p>The Query Execution Engine (QXE)</p>\n<ul>\n<li>optimizing state output query execution plan => QXE (data structure, not byte-code)</li>\n<li>handler API</li>\n</ul>\n</li>\n<li>\n<p>Return data to the client</p>\n<ul>\n<li>If query is cacheable cache it</li>\n<li>As soon as mysql processes the last table and generates 1 row => send data to client</li>\n<li>Each row in the result set is sent in a separate packet mysql client/server protocol</li>\n</ul>\n</li>\n<li>\n<p>Subquery vs join</p>\n<ul>\n<li>GROUP_CONCAT</li>\n<li>IN vs EXISTS</li>\n<li>Measure</li>\n<li>UNION LIMIT</li>\n</ul>\n</li>\n<li>Index Merge Optimizations</li>\n<li>Equality Propagation: e.g: IN list WHERE, ON, USING the optimizer will share the list by copying => can be slow</li>\n<li>Parallel Execution: not support, 8.0.14 limited support</li>\n<li>\n<p>Hash joins:</p>\n<ul>\n<li>Mysql 5.6 not support only nested-loop join, support in MySql 8, mariadb 5.3, 5.5 support BNL, BNLH, BKA, BKAH.</li>\n<li><code class=\"language-text\">index condition pushdown</code> loose index scan</li>\n<li><code class=\"language-text\">MIN()</code> and <code class=\"language-text\">MAX()</code> optimize: </li>\n</ul>\n</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SELECT MIN(actor_id) FROM sakila.actor WHERE first_name = &#39;PENELOPE&#39;; \nscan entire table</code></pre></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SELECT actor_id FROM sakila.actor USE INDEX(PRIMARY) WHERE first_name = &#39;PENELOPE&#39; LIMIT 1;\nfix</code></pre></div>\n<ul>\n<li>SELECT and UPDATE on the Same Table…</li>\n<li>Query Optimizer Hints</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">HIGH_PRIORITY and LOW_PRIORITY\nDELAYED\nSTRAIGHT_JOIN\nSQL_SMALL_RESULT and SQL_BIG_RESULT\nSQL_BUFFER_RESULT\nSQL_CACHE and SQL_NO_CACHE\nSQL_CALC_FOUND_ROWS\nFOR UPDATE and LOCK IN SHARE MODE\nUSE INDEX, IGNORE INDEX, and FORCE INDEX\noptimizer_search_depth\noptimizer_prune_level\noptimizer_switch</code></pre></div>\n<ul>\n<li>optimizing count</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SELECT COUNT(*) FROM world.City WHERE ID &gt; 5;\nto\nSELECT (SELECT COUNT(*) FROM world.City) - COUNT(*)\nFROM world.City WHERE ID &lt;= 5;\n\ncount multiple column\nSELECT SUM(IF(color = &#39;blue&#39;, 1, 0)) AS blue,SUM(IF(color = &#39;red&#39;, 1, 0)) AS red FROM items\nor \nSELECT COUNT(color = &#39;blue&#39; OR NULL) AS blue, COUNT(color = &#39;red&#39; OR NULL) AS red FROM items;\n- using approximation\n- covering index\n- summary tables\n- cache </code></pre></div>\n<ul>\n<li>optimizing join</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">- ON, USING: use indexes\n- GROUP BY, ORDER BY expression refers only to column from single table</code></pre></div>\n<ul>\n<li>optimizing subqueries</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">- mysql &lt; 5.6 join wherever possible\n- 5.6+ or mariadb measure it?</code></pre></div>\n<ul>\n<li>\n<p>optimizing group by, distinct</p>\n<ul>\n<li>use indexes</li>\n<li>when mysql can’t use indexes: 1-filesort, 2-temporary table</li>\n<li>group by identifier rather than by the value (group join value from lookup table)</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SELECT actor.first_name, actor.last_name, COUNT(*)  \nFROM sakila.film_actor    \nINNER JOIN sakila.actor USING(actor_id)    \nGROUP BY actor.first_name, actor.last_name;\nto:\nSELECT actor.first_name, actor.last_name, COUNT(*)    \nFROM sakila.film_actor    \nINNER JOIN sakila.actor USING(actor_id)    \nGROUP BY film_actor.actor_id; // film.actor_id\n\nabout:\nSELECT actor.first_name, actor.last_name, c.cnt    \nFROM sakila.actor    \nINNER JOIN (    \nSELECT actor_id, COUNT(*) AS cnt    \nFROM sakila.film_actor    \nGROUP BY actor_id) AS c USING(actor_id) ;\ncreating and filling the temporary table required for the subquery maybe high compared to the cost of fudging pure relational theory a little bit</code></pre></div>\n<p><strong>temporary table created by the subquery has no indexes</strong></p>\n<ul>\n<li>Optimizing GROUP BY WITH ROLLUP</li>\n</ul>\n</li>\n<li>\n<p>Optimizing LIMIT and OFFSET</p>\n<ul>\n<li>deferred join</li>\n<li>precompute <code class=\"language-text\">SELECT film_id, description FROM sakila.film    -&gt; WHERE position BETWEEN 50 AND 54 ORDER BY position;</code></li>\n<li>If you use a sort of bookmark to remember the position of the last row you fetched,\nyou can generate the next set of rows by starting from that position instead of using an OFFSET</li>\n</ul>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">SELECT * FROM sakila.rental    \nORDER BY rental_id DESC LIMIT 20;\nreturn 16049 through 16030\n=&gt;\nSELECT * FROM sakila.rental    \nWHERE rental_id &lt; 16030    \nORDER BY rental_id DESC LIMIT 20;</code></pre></div>\n<ul>\n<li>Use Sphinx</li>\n</ul>\n</li>\n<li>\n<p>Optimizing UNION</p>\n<ul>\n<li>MySQL always executes UNION queries by creating a temporary table and filling it withthe UNION results</li>\n<li>always  use UNION  ALL,  unless  you  need  the  server  to  eliminateduplicate rows</li>\n<li>the ALL keyword doesn’t eliminate the temporary table</li>\n</ul>\n</li>\n</ul>\n<p><em>Static Query Analysis</em>: Percona Toolkit </p>\n<ul>\n<li>Using User-Defined Variables</li>\n</ul>","frontmatter":{"title":"Optimize MySQL","date":"February 24, 2021","description":"Basic MySQL optimization techniques"}}},"pageContext":{"slug":"/mysql/mysql/","previous":{"fields":{"slug":"/todo/todo/"},"frontmatter":{"title":"TODO"}},"next":null}},"staticQueryHashes":["2103919173","2841359383"]}